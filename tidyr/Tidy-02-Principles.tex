Tidy data

Tidy data is a standard way of mapping the meaning of a dataset to its structure. A dataset is messy or tidy depending on how rows, columns and tables are matched up with observations, variables and types. In tidy data:

\begin{itemize}
\item Each variable forms a column.
\item Each observation forms a row.
\item Each type of observational unit forms a table.
\end{itemize}

This is Codd's 3rd normal form, but with the constraints framed in statistical language, and the focus put on a single dataset rather than the many connected datasets common in relational databases. Messy data is any other other arrangement of the data.

Tidy data makes it easy for an analyst or a computer to extract needed variables because it provides a standard way of structuring a dataset. Compare the different versions of the pregnancy data: in the messy version you need to use different strategies to extract different variables. This slows analysis and invites errors. If you consider how many data analysis operations involve all of the values in a variable (every aggregation function), you can see how important it is to extract these values in a simple, standard way. Tidy data is particularly well suited for vectorised programming languages like R, because the layout ensures that values of different variables from the same observation are always paired.

While the order of variables and observations does not affect analysis, a good ordering makes it easier to scan the raw values. One way of organising variables is by their role in the analysis: are values fixed by the design of the data collection, or are they measured during the course of the experiment? Fixed variables describe the experimental design and are known in advance. Computer scientists often call fixed variables dimensions, and statisticians usually denote them with subscripts on random variables. Measured variables are what we actually measure in the study. Fixed variables should come first, followed by measured variables, each ordered so that related variables are contiguous. Rows can then be ordered by the first variable, breaking ties with the second and subsequent (fixed) variables. This is the convention adopted by all tabular displays in this paper.

%====================================================================%
Tidying messy datasets {#sec:tidying}

Real datasets can, and often do, violate the three precepts of tidy data in almost every way imaginable. While occasionally you do get a dataset that you can start analysing immediately, this is the exception, not the rule. This section describes the five most common problems with messy datasets, along with their remedies:

\begin{itemize}
\item Column headers are values, not variable names.
\item Multiple variables are stored in one column.
\item Variables are stored in both rows and columns.
\item Multiple types of observational units are stored in the same table.
\item A single observational unit is stored in multiple tables.
\end{itemize}

Surprisingly, most messy datasets, including types of messiness not explicitly described above, can be tidied with a small set of tools: gathering, separating and spreading. The following sections illustrate each problem with a real dataset that I have encountered, and show how to tidy them.

Column headers are values, not variable names

A common type of messy dataset is tabular data designed for presentation, where variables form both the rows and columns, and column headers are values, not variable names. While I would call this arrangement messy, in some cases it can be extremely useful. It provides efficient storage for completely crossed designs, and it can lead to extremely efficient computation if desired operations can be expressed as matrix operations.

The following code shows a subset of a typical dataset of this form. This dataset explores the relationship between income and religion in the US. It comes from a report1 produced by the Pew Research Center, an American think-tank that collects data on attitudes to topics ranging from religion to the internet, and produces many reports that contain datasets in this format.

pew <- tbl_df(read.csv("pew.csv", stringsAsFactors = FALSE, check.names = FALSE))
pew
#> Source: local data frame [18 x 11]
#> 
#>                   religion <$10k $10-20k $20-30k $30-40k $40-50k $50-75k
#> 1                 Agnostic    27      34      60      81      76     137
#> 2                  Atheist    12      27      37      52      35      70
#> 3                 Buddhist    27      21      30      34      33      58
#> 4                 Catholic   418     617     732     670     638    1116
#> 5       Don’t know/refused    15      14      15      11      10      35
#> 6         Evangelical Prot   575     869    1064     982     881    1486
#> 7                    Hindu     1       9       7       9      11      34
#> 8  Historically Black Prot   228     244     236     238     197     223
#> 9        Jehovah's Witness    20      27      24      24      21      30
#> 10                  Jewish    19      19      25      25      30      95
#> ..                     ...   ...     ...     ...     ...     ...     ...
#> Variables not shown: $75-100k (int), $100-150k (int), >150k (int), Don't
#>   know/refused (int)
This dataset has three variables, religion, income and frequency. To tidy it, we need to gather the non-variable columns into a two-column key-value pair. This action is often described as making a wide dataset long (or tall), but I'll avoid those terms because they're imprecise.

When gathering variables, we need to provide the name of the new key-value columns to create. The first argument, is the name of the key column, which is the name of the variable defined by the values of the column headings. In this case, it's income. The second argument is the name of the value column, frequency. The third argument defines the columns to gather, here, every column except religion.

pew %>%
  gather(income, frequency, -religion)
#> Source: local data frame [180 x 3]
#> 
#>                   religion income frequency
#> 1                 Agnostic  <$10k        27
#> 2                  Atheist  <$10k        12
#> 3                 Buddhist  <$10k        27
#> 4                 Catholic  <$10k       418
#> 5       Don’t know/refused  <$10k        15
#> 6         Evangelical Prot  <$10k       575
#> 7                    Hindu  <$10k         1
#> 8  Historically Black Prot  <$10k       228
#> 9        Jehovah's Witness  <$10k        20
#> 10                  Jewish  <$10k        19
#> ..                     ...    ...       ...
This form is tidy because each column represents a variable and each row represents an observation, in this case a demographic unit corresponding to a combination of religion and income.

This format is also used to record regularly spaced observations over time. For example, the Billboard dataset shown below records the date a song first entered the billboard top 100. It has variables for artist, track, date.entered, rank and week. The rank in each week after it enters the top 100 is recorded in 75 columns, wk1 to wk75. This form of storage is not tidy, but it is useful for data entry. It reduces duplication since otherwise each song in each week would need its own row, and song metadata like title and artist would need to be repeated. This will be discussed in more depth in (multiple types)[#multiple-types].

billboard <- tbl_df(read.csv("billboard.csv", stringsAsFactors = FALSE))
billboard
#> Source: local data frame [317 x 81]
#> 
#>    year         artist                   track time date.entered wk1 wk2
#> 1  2000          2 Pac Baby Don't Cry (Keep... 4:22   2000-02-26  87  82
#> 2  2000        2Ge+her The Hardest Part Of ... 3:15   2000-09-02  91  87
#> 3  2000   3 Doors Down              Kryptonite 3:53   2000-04-08  81  70
#> 4  2000   3 Doors Down                   Loser 4:24   2000-10-21  76  76
#> 5  2000       504 Boyz           Wobble Wobble 3:35   2000-04-15  57  34
#> 6  2000           98^0 Give Me Just One Nig... 3:24   2000-08-19  51  39
#> 7  2000        A*Teens           Dancing Queen 3:44   2000-07-08  97  97
#> 8  2000        Aaliyah           I Don't Wanna 4:15   2000-01-29  84  62
#> 9  2000        Aaliyah               Try Again 4:03   2000-03-18  59  53
#> 10 2000 Adams, Yolanda           Open My Heart 5:30   2000-08-26  76  76
#> ..  ...            ...                     ...  ...          ... ... ...
#> Variables not shown: wk3 (int), wk4 (int), wk5 (int), wk6 (int), wk7
#>   (int), wk8 (int), wk9 (int), wk10 (int), wk11 (int), wk12 (int), wk13
#>   (int), wk14 (int), wk15 (int), wk16 (int), wk17 (int), wk18 (int), wk19
#>   (int), wk20 (int), wk21 (int), wk22 (int), wk23 (int), wk24 (int), wk25
#>   (int), wk26 (int), wk27 (int), wk28 (int), wk29 (int), wk30 (int), wk31
#>   (int), wk32 (int), wk33 (int), wk34 (int), wk35 (int), wk36 (int), wk37
#>   (int), wk38 (int), wk39 (int), wk40 (int), wk41 (int), wk42 (int), wk43
#>   (int), wk44 (int), wk45 (int), wk46 (int), wk47 (int), wk48 (int), wk49
#>   (int), wk50 (int), wk51 (int), wk52 (int), wk53 (int), wk54 (int), wk55
#>   (int), wk56 (int), wk57 (int), wk58 (int), wk59 (int), wk60 (int), wk61
#>   (int), wk62 (int), wk63 (int), wk64 (int), wk65 (int), wk66 (lgl), wk67
#>   (lgl), wk68 (lgl), wk69 (lgl), wk70 (lgl), wk71 (lgl), wk72 (lgl), wk73
#>   (lgl), wk74 (lgl), wk75 (lgl), wk76 (lgl)
To tidy this dataset, we first gather together all the wk columns. The column names give the week and the values are the ranks:

billboard2 <- billboard %>% 
  gather(week, rank, wk1:wk76, na.rm = TRUE)
billboard2
#> Source: local data frame [5,307 x 7]
#> 
#>    year         artist                   track time date.entered week rank
#> 1  2000          2 Pac Baby Don't Cry (Keep... 4:22   2000-02-26  wk1   87
#> 2  2000        2Ge+her The Hardest Part Of ... 3:15   2000-09-02  wk1   91
#> 3  2000   3 Doors Down              Kryptonite 3:53   2000-04-08  wk1   81
#> 4  2000   3 Doors Down                   Loser 4:24   2000-10-21  wk1   76
#> 5  2000       504 Boyz           Wobble Wobble 3:35   2000-04-15  wk1   57
#> 6  2000           98^0 Give Me Just One Nig... 3:24   2000-08-19  wk1   51
#> 7  2000        A*Teens           Dancing Queen 3:44   2000-07-08  wk1   97
#> 8  2000        Aaliyah           I Don't Wanna 4:15   2000-01-29  wk1   84
#> 9  2000        Aaliyah               Try Again 4:03   2000-03-18  wk1   59
#> 10 2000 Adams, Yolanda           Open My Heart 5:30   2000-08-26  wk1   76
#> ..  ...            ...                     ...  ...          ...  ...  ...
Here we use na.rm to drop any missing values from the gather columns. In this data, missing values represent weeks that the song wasn't in the charts, so can be safely dropped.

In this case it's also nice to do a little cleaning, converting the week variable to a number, and figuring out the date corresponding to each week on the charts:

billboard3 <- billboard2 %>%
  mutate(
    week = extract_numeric(week),
    date = as.Date(date.entered) + 7 * (week - 1)) %>%
  select(-date.entered)
billboard3
#> Source: local data frame [5,307 x 7]
#> 
#>    year         artist                   track time week rank       date
#> 1  2000          2 Pac Baby Don't Cry (Keep... 4:22    1   87 2000-02-26
#> 2  2000        2Ge+her The Hardest Part Of ... 3:15    1   91 2000-09-02
#> 3  2000   3 Doors Down              Kryptonite 3:53    1   81 2000-04-08
#> 4  2000   3 Doors Down                   Loser 4:24    1   76 2000-10-21
#> 5  2000       504 Boyz           Wobble Wobble 3:35    1   57 2000-04-15
#> 6  2000           98^0 Give Me Just One Nig... 3:24    1   51 2000-08-19
#> 7  2000        A*Teens           Dancing Queen 3:44    1   97 2000-07-08
#> 8  2000        Aaliyah           I Don't Wanna 4:15    1   84 2000-01-29
#> 9  2000        Aaliyah               Try Again 4:03    1   59 2000-03-18
#> 10 2000 Adams, Yolanda           Open My Heart 5:30    1   76 2000-08-26
#> ..  ...            ...                     ...  ...  ...  ...        ...
Finally, it's always a good idea to sort the data. We could do it by artist, track and week:

billboard3 %>% arrange(artist, track, week)
#> Source: local data frame [5,307 x 7]
#> 
#>    year  artist                   track time week rank       date
#> 1  2000   2 Pac Baby Don't Cry (Keep... 4:22    1   87 2000-02-26
#> 2  2000   2 Pac Baby Don't Cry (Keep... 4:22    2   82 2000-03-04
#> 3  2000   2 Pac Baby Don't Cry (Keep... 4:22    3   72 2000-03-11
#> 4  2000   2 Pac Baby Don't Cry (Keep... 4:22    4   77 2000-03-18
#> 5  2000   2 Pac Baby Don't Cry (Keep... 4:22    5   87 2000-03-25
#> 6  2000   2 Pac Baby Don't Cry (Keep... 4:22    6   94 2000-04-01
#> 7  2000   2 Pac Baby Don't Cry (Keep... 4:22    7   99 2000-04-08
#> 8  2000 2Ge+her The Hardest Part Of ... 3:15    1   91 2000-09-02
#> 9  2000 2Ge+her The Hardest Part Of ... 3:15    2   87 2000-09-09
#> 10 2000 2Ge+her The Hardest Part Of ... 3:15    3   92 2000-09-16
#> ..  ...     ...                     ...  ...  ...  ...        ...
Or by date and rank:

billboard3 %>% arrange(date, rank)
#> Source: local data frame [5,307 x 7]
#> 
#>    year   artist  track time week rank       date
#> 1  2000 Lonestar Amazed 4:25    1   81 1999-06-05
#> 2  2000 Lonestar Amazed 4:25    2   54 1999-06-12
#> 3  2000 Lonestar Amazed 4:25    3   44 1999-06-19
#> 4  2000 Lonestar Amazed 4:25    4   39 1999-06-26
#> 5  2000 Lonestar Amazed 4:25    5   38 1999-07-03
#> 6  2000 Lonestar Amazed 4:25    6   33 1999-07-10
#> 7  2000 Lonestar Amazed 4:25    7   29 1999-07-17
#> 8  2000    Amber Sexual 4:38    1   99 1999-07-17
#> 9  2000 Lonestar Amazed 4:25    8   29 1999-07-24
#> 10 2000    Amber Sexual 4:38    2   99 1999-07-24
#> ..  ...      ...    ...  ...  ...  ...        ...
